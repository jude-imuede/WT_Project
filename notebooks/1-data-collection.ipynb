{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Twitter Data Collection for WITS University\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Invoke expected libraries\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import datetime\n",
    "from datetime import datetime, date, time, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Input Twitter Credentials\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'QkOPEf30YeLfJArtcyTbqFrVo'\n",
    "consumer_secret = '8lZqb1zrlDKT3QpoYQjANczRRF9Kp1wGnM64qqLkjjIQdf4nLB'\n",
    "access_token = '248586805-hUftzAY5Co6bfx4k3QNYadmDFJbyJKptTjbfgfNW'\n",
    "access_token_secret = 'qqrIb5JfKkeX8eX8w6v9HeMvRpj8tAVCPHfXyQpuoaV1H'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Authenticate with the Twitter API\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: Write to a CSV file\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open/Create a file in append mode\n",
    "# csvFile = open('../data/raw/WitsTweets-'+timestamp+\".csv\", 'a')\n",
    "# #csvFile = open('../data/raw/WitsTweets5000.csv')\n",
    "# csvWriter = csv.writer(csvFile)\n",
    "\n",
    "# Open/Create a file to append data\n",
    "csvFile = open('../data/raw/tweets.csv', 'a')\n",
    "#Use csv Writer\n",
    "csvWriter = csv.writer(csvFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5: Specify track, search or keywords specific to WITS University.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect Tweets and Desired Attributes\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Collecting Tweets\")\n",
    "for tweet in tweepy.Cursor(api.search,q=\"WITS OR wits OR Witsaccommodation OR WitsAccommodation OR WitsExam OR Wits OR WitsUniversity OR WITSUniversity OR University of the Witwatersrand OR Witsie OR WitsEntrolment OR AdamHabib -filter:retweets\", count=20000,\\\n",
    "#for tweet in tweepy.Cursor(api.search,q=\"WITS\", \"Wits\", \"wits\", \"Witsaccommodation\", \"WitsAccommodation\", \"WitsExam\", \"WitsUniversity\", \"WITSUniversity\", \"University of the Witwatersrand\", \"Witsie\", \"WitsEntrolment\", \"AdamHabib\", -filter:retweets, count=20000,\\\n",
    "                           lang=\"en\",\\\n",
    "                           #tweet_mode = 'extended',\\\n",
    "                           since_id=2020-1-1).items():\n",
    "                           #since=\"2020-01-01\",\n",
    "                          # until=\"2020-01-06\"\n",
    "                    \n",
    "                           #include_entities=True).items(): \n",
    "#     print tweet.created_at, tweet.text\n",
    "#     csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])                      \n",
    "                           \n",
    "                           \n",
    "        \n",
    "    \n",
    "    tweet_hashtags = ''\n",
    "    \n",
    "    \n",
    "    if tweet.entities['hashtags'] == []: # no hash tag\n",
    "        tweet_hashtags = None\n",
    "    else:\n",
    "        tweet_hashtags = \"-\".join([ dic['text'] for dic in tweet.entities['hashtags']])\n",
    "    \n",
    "\n",
    "#for tweet in results:\n",
    "#print(tweet.get('user', {}).get('location', {}))\n",
    "    \n",
    "# Extract Tweet Attributes in these Sequence\n",
    "    location = tweet.user.location\n",
    "    #print(location)\n",
    "    tweet_time  = tweet.created_at\n",
    "    twitter_user = tweet.user.screen_name\n",
    "    tweet_url = \"https://twitter.com/\" +twitter_user +\"/status/\"+ tweet.id_str\n",
    "    tweet_text =  tweet.full_text\n",
    "\n",
    "\n",
    "    # Create Record for the collected Tweet in the form of a DataFrame\n",
    "    tweet_record = [tweet_time, twitter_user, tweet_text.strip(), tweet_url, location,tweet_hashtags]\n",
    "\n",
    "    # Append the Tweet Record to the CSV File\n",
    "    csvWriter.writerow(tweet_record)\n",
    "\n",
    "print(\"Done Collecting Tweets\")\n",
    "print(\"---------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
